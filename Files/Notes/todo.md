# Coisas a fazermos

> Focar na operacionaliza√ß√£o e nos impactos das LLMs.

- Baselines
  - [x] Descobrir quais
  - [x] Quais s√£o as baselines cl√°ssicas?
    - R:
      - OpenTag
      - BiLSTM-CRF
      - AVEQA
      - SUOT
  - [ ] Implementar
    - R: WIP
  - [ ] Come√ßar pelo melhor que j√° existe
- Dimens√µes de teste: O que com quem?
  1. Modelos:
     1. Modelos pr√©-treinados nessa tarefa (liquid.ai lfm2-extract (Upperbound), Lang Extract: framework do Google (Comercial)), Gen√©ricos, Fine-Tuned
     2. Tamanho do modelo
     3. Fam√≠lias de LLMs
  2. Prompts: Que prompts usar? Ficar testando e se basear no que j√° usaram pra ver que diferen√ßa faz.
     1. Zero-Shot, Few-Shot
  3. Datasets:
     1. MAVE, TREC, AE-110K, OA-Mine
- Avalia√ß√£o
  - [ ] Precis√£o
  - [ ] Recall
  - [ ] F1-Score
  - [ ] Procurar quais outras m√©tricas s√£o usadas na literatura e j√° est√£o implementadas.
  - [ ] Procurar bibliotecas.

---

- Escopo
- Fora do escopo
  - Escalabilidade para e-commerce
  - Apresenta√ß√£o dos produtos

---

- D√∫vida
  - P: Extrair atributo de Imagem?
    - R: N√£o, focar em texto.
  - P: Extrair atributos de produtos similares?
    - R: Sim.
  - P: Categorizar?
    - R: N√£o, mas pode ser um potencial aprimoramento futuro.
  - P: Recategorizar?
    - R: N√ÉO, mas...
  - P: Testar em categorias diferentes?
    - R: Inicialmente s√≥ uma categoria. Potencial expans√£o posterior.
  - P: Quais as limita√ß√µes dos datasets e das baselines?
    - R: Pesquisar posteriormente.
  - P: O que √© esse autoaperfei√ßoamento?
    - R: Pesquisar posteriormente.

## Tarefas

### üí†

- [ ] Baixar o dataset AE-110K e entender como ele conecta no BiLSTM-CRF.
- [ ] Aplicar os m√©todos de avalia√ß√£o (Precis√£o, Recall, F1) no pipeline atual.
- [ ] Fazer o nosso (conversar depois)

### üçØ

- [ ] Clonando o BiLSTM-CRF e avaliando como conectar no dataset.
- [ ] Como conectar o BiLSTM-CRF com as m√©tricas de avalia√ß√£o.
- [ ] Fazer o nosso (conversar depois)
